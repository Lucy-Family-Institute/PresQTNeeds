<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>PresQT Needs Assessment Results</title>

    <!-- Include Bootstrap styles-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

<!-- Load c3.css -->
<link href="c3.css" rel="stylesheet">
<style>
.scroll {
    height: 300px;
    overflow-y: scroll;
}
</style>

    </head>
    <body>
        <div class="container">
       <h1>PresQT Needs Assessment Results</h1>
            <p>In the Summer/Fall of 2017 Participants were invited to contribute answers for the PresQT research study, 
            entitled "Data and Software Preservation Quality Tool Needs Assessment" related to the
            <a href = "https://osf.io/d3jx7/">PresQT Project</a>, University of Notre Dame Study 
            # 17-04-3850 DOI 10.17605/OSF.IO/D3JX7. Data Collection 
            closed Sept 1, 2017 at 5 PM EDT. Participants' answers to a series of questions related
            to their past practice, and anticipated future needs as researchers and/or software developers
            contribute to a better understanding of what tools and/or tool suites would be of benefit those preserving and/or sharing data and software. </p>

            
            <p>The Needs Assessment questionnaire and response data are available on the <a href="https://osf.io/xfws6/">project page</a>.</p>
        <ul>
            <li><a href="https://osf.io/xzhau/">Questionnaire</a> (PDF)</li>
            <li><a href="https://osf.io/6v325/">Data</a></li>
        </ul>
<!-- Load d3.js and c3.js -->
<script src="d3.v3.min.js"></script>
<script src="c3.min.js"></script>
<script>
var charts = {}

var colorlist = ["#16a085", "#aac7a6", "#ffc300", "#aa8888", "#c70039", "#900c3f", "#555555"]


var make_pie = function (id, datalist) {
    var colors = {}
    for(i=0; i < datalist.length; i++){
        colors[datalist[i][0]] = colorlist[i]
    }
    charts[id] = c3.generate({
        bindto: "#" + id,
        data: {
            type: 'pie',
            colors: colors,
            order: null,
            columns: datalist
        }})
}
</script>

        <hr>

        <h1>Tools/Usefulness/Sort</h1>

        <h3>Indicate whether implementation or integration of tools like those below would 
ease your path to publishing, sharing, curating, or reusing data or software:
        <small class="text-muted">(tools_use_matrix)</small>
        </h3>

        <div id="tools_use_matrix"></div>

    <script>
    var tools_use_matrix = c3.generate({
        bindto: "#tools_use_matrix",
        axis: {
            x: { type: 'category'},
            rotated: true
        },
        data: {
            type: 'bar',
            order: null,
            colors: {
                'Extremely useful': colorlist[0],
                'Useful': colorlist[1],
                'Somewhat useful': colorlist[2],
                'Not useful': colorlist[3]
            },
            x: 'x',
            groups: [['Extremely useful', 'Useful', 'Somewhat useful',  'Not useful']],
            rows:[
                ['x', 'Extremely useful', 'Useful', 'Somewhat useful',  'Not useful'],
                ['Provenance', 554, 554, 276, 86],
                ['Workflow', 516, 533, 301, 117],
                ['Fixity', 341, 580, 384, 148],
                ['Assignment', 275, 522, 451, 209],
                ['Profile Based Recommender', 156, 469, 541, 292],
                ['De-identification', 325, 390, 380, 368],
                ['Quality', 338, 559, 381, 184]
           ]}});
    </script>

        <h3>Do you have a data or software preservation quality tool need this project could help you develop ? If so, please describe:
        <small class="text-muted">(tools_data_preserv)</small>
        </h3>

        <p>Sample of responses:</p>
        <ul class="list-group scroll">

            <li class="list-group-item">4CeeD cloud-based system that collects data and metadata from microscopes, and then allows scientists to curate the data on the cloud.</li>
            <li class="list-group-item">A 'map of the data preservation' landscape showing canonical repositories, types of data it stores, metadata requirements, costs, etc.</li>
            <li class="list-group-item">A Thermodynamic model</li>
            <li class="list-group-item">A clear way to save large MD trajectory files that is cost-effective</li>
            <li class="list-group-item">A major challenge in my main field, which is molecular dynamics simulation, is the question of how to share and curate simulation trajectory files. These files are the base output of every molecular dynamics run - they are the equivalent of providing a sample of a material itself in experiment. The central challenge is that these files are very large (we have ca. 100 TB of trajectory files from our group alone). It is also extremely difficult to track their provenance and the precise metadata associated with the conditions under which they were generated. Nevertheless, a facile ability to share these files among the community could exponentially amplify the communities productivity by permitting renanalysis of existing trajectories, rather than a constant need to redo work someone else has done. There is presently no good solution.</li>
            <li class="list-group-item">A place put large ([greater than] 1 TB) datasets (and associated metadata) for preservation at no cost to the data producer and that will remain publicly accessible. Preferably, this service would have an API so that datasets could be easily integrated into other services.</li>
            <li class="list-group-item">A suite of R packages for reproducibility</li>
            <li class="list-group-item">A tool that can assess what needs to be preserved / documented to maintain long-term access to data and software</li>
            <li class="list-group-item">A tool that would ensure that a proper lab-book/log entry was provided for each data recording session. A generalized and very fast/easy tool for checking in data analysis lab book entries. It's fine to have analysis code, but without a lab book and demo/docs its nearly impossible to run or understand the code.</li>
            <li class="list-group-item">A version system that is good with videos or specific files with software such as Unity3D or Autodesk Maya</li>
            <li class="list-group-item">A way of identifying the right repository for my data.</li>
            <li class="list-group-item">All of my projects work with speech and natural language data, therefore I have extensive experience creating and deploying software solving all fo the problems mentioned on previous page</li>
            <li class="list-group-item">All of the things on the previous page would be useful</li>
            <li class="list-group-item">Already have sufficient tools for this.</li>
            <li class="list-group-item">Anonymization of data; version control;tools to ensure integrity of data files</li>
            <li class="list-group-item">Any tools for developing and sharing ontologies in OWL.</li>
            <li class="list-group-item">Anything that helps tracking who, when or what data were added or changed. Overall tracking of projects and project-based metadata standards  are needed. One huge problem in data preservation is lack of translation services that allow data in obsolete software or stored on obsolete hardware to re recovered more easily.</li>
            <li class="list-group-item">As part of a user facility:  we are developing data & software preservation protocols right now, so suggestions of current best practices and canned tools could be very helpful</li>
            <li class="list-group-item">Assigning DOIs to datasets. Finding relationships among disparate datasets and mapping concepts across them</li>
            <li class="list-group-item">Basic spectral data format</li>
            <li class="list-group-item">Better integration of version control software and ids that describe what revision of a software was used for publications</li>
            <li class="list-group-item">Collecting data from social media</li>
            <li class="list-group-item">Comparison of hosted platforms</li>
            <li class="list-group-item">Computational and experimental data. Software.</li>
            <li class="list-group-item">Could use a tool that can apply anonymized identifiers across multiple data files.</li>
            <li class="list-group-item">Curate instances of code used in published papers where that code has now been developed further.</li>
            <li class="list-group-item">Currently using Samvera, which does not make it easy to export metadata to create an offsite archival copy. Currently my biggest need for our repository!</li>
            <li class="list-group-item">Currently using available tools to track and preserve software and data.</li>
            <li class="list-group-item">Currently we archive our data with the LTER Network Information System (NIS) Data Portal. However, as we move forward with new projects we will have other csv files that needs to be archived/preserved.  Right now we are planning to use curateND for those files.</li>
            <li class="list-group-item">Custom student data for educational research in STEM</li>
            <li class="list-group-item">Customers of an institute I run may have this need.</li>
            <li class="list-group-item">Data Mining on Big Data for Automated User Profiling</li>
            <li class="list-group-item">Data collected from children's learning app, so privacy/anonymization of students' identities is crucial.  This data is currently stored in set of SQL tables.</li>
            <li class="list-group-item">Data from engineering education study</li>
            <li class="list-group-item">Data from insurance claims that need to be made anonymous</li>
            <li class="list-group-item">Data from robotic telescope</li>
            <li class="list-group-item">Data need. Test and analysis data and softwares used to generate the analytical data.</li>
            <li class="list-group-item">Data tool for archiving evaluation plans for citation [see] the recent AERA-NSF workshop on data sharing and transparency.</li>
            <li class="list-group-item">Database of observational data</li>
            <li class="list-group-item">Databases of mathematical classifications (similar to crystolography tables) that need timeless and language independent modelling.</li>
            <li class="list-group-item">De-anonymization</li>
            <li class="list-group-item">De-identification of qualitative data (e.g., video or screencapture). Project level organization of data.</li>
            <li class="list-group-item">Different types of phylogenomic data (sequences, SNPs) and data processing and analysis pipelines.</li>
            <li class="list-group-item">Don't know - not sure what "this project" is and what resources are available to researchers outside of Notre Dame.</li>
            <li class="list-group-item">Don't think so</li>
            <li class="list-group-item">Drupal or Wordpress plug-ins for data quality/management tasks.</li>
            <li class="list-group-item">Easy metadata entry and retrieval</li>
            <li class="list-group-item">Easy to use database to identify projects, users, etc. associated with large batches of raw data.</li>
            <li class="list-group-item">FLexible system for creating meta data when uploading unstructured datasets</li>
            <li class="list-group-item">GitHub</li>
            <li class="list-group-item">How to make ethnographic interviews anonymous in multiple languages.</li>
            <li class="list-group-item">How to preserve linux command pipelines from bioinformatic analyses?</li>
            <li class="list-group-item">I am developing a search engine where the search index should be shared but it is too big to be simply uploaded.</li>
            <li class="list-group-item">I am involved in developing preservation of workflows in computational modeling</li>
            <li class="list-group-item">I am not sure but we are developing a software in Matlab as a part of the project</li>
            <li class="list-group-item">I am not sure what "this project" does, so that's hard to answer. In general, though, I think it is more a 'community' level issue, rather than an individual researcher need.</li>
            <li class="list-group-item">I am not sure. I am working on a global millipede species database, MilliBase.org. Currently, I think we are doing ok.</li>
            <li class="list-group-item">I collect experimental data and would like to do a better job of archiving it.</li>
            <li class="list-group-item">I do but I am not sure a general purpose tool could help.</li>
            <li class="list-group-item">I generate lots of data...</li>
            <li class="list-group-item">I have A LOT of different kinds of data (video, written, digital artifacts, etc.) - it would be really useful if there were some sort of tool that allowed me to organize all of that data so that it could be easier to analyze it.</li>
            <li class="list-group-item">I have a large amount of coal geochemical and petrographic data gathered over the past 39 years.</li>
            <li class="list-group-item">I have a project archiving information on survey data quality. contact me another way to discuss this</li>
            <li class="list-group-item">I have a stellar population synthesis code that is managed on bitbucket, but could probably be better managed. This is particularly true because part of the software makes use or large training sets that are themselves too large to be managed on bitbucket. At present they are just stored on our group's website without any real version control.</li>
            <li class="list-group-item">I have been developing modeling software for 10+years focused on a single project, and it has gone through many revisions and extensions.</li>
            <li class="list-group-item">I have data [and] software to preserve, but am wary of another source or group that wants to deal with this other than myself</li>
            <li class="list-group-item">I have data from electronic structure calculations (VASP) from which pieces are extracted and then stored and analyzed in Excel spreadsheets. Very inconvenient for long term storage.</li>
            <li class="list-group-item">I have many types of data from -omics to ecosystem fluxes to imagery.</li>
            <li class="list-group-item">I know of several tools that do parts of the process, but having a tool that navigates the expositions tools would be great (and meta!). It would also be easier for me to find the gaps and answer this question, since different projects require different tools.</li>
            <li class="list-group-item">I mainly need something that makes it easy to archive large numbers of large files (the lab can easily generate more than 1 GB of data per day if we wanted to) and ideally also makes it easy to tag them with various metadata.</li>
            <li class="list-group-item">I only do qualitative research and use NVivo or HyperResearch to manage my text based data</li>
            <li class="list-group-item">I produce artifacts for almost every one of my papers, so I have dozens??_</li>
            <li class="list-group-item">I recommend that imaging data be stored as fits fiiles</li>
            <li class="list-group-item">I run the Paleobiology Database, and we would like to create archivable snapshots of the database for reference.</li>
            <li class="list-group-item">I struggle with how to combine usage of GitHub for collaboration on data with long-term data storage. Ideally, I'd want only one copy of each dataset, but I'm not sure GitHub is the correct location for long-term storage, therefore I have to either have two copies of datasets, or temporarily move things to GitHub and then to long-term storage.</li>
            <li class="list-group-item">I use LTER Network tools.</li>
            <li class="list-group-item">I use a variety of existing software packages that address all or most of the issues in the previous question.</li>
            <li class="list-group-item">I wish there were tools for more easily documenting changes to query structure in relational databases.</li>
            <li class="list-group-item">I work in chemistry. I would like disparate data to carry an RFID like tag that can easily collated by another software rather than forcing the student to always curate. Automate the coherent collection of all data into one location</li>
            <li class="list-group-item">I work with Google Docs. I'm not sure that is what you mean.</li>
            <li class="list-group-item">I work with fossils from other countries that I photograph for future use - these are not particularly well-preserved fossils and they are identified to different taxonomic levels. I'd like a place to deposit these images and have them be searchable and groups based on stratigraphic relationships (I think Marcostrat and PaleoBioDB have attempted this, but they don't have a place for many many many photos)</li>
            <li class="list-group-item">I would like to digitize and organize data from cabinets at a field station.</li>
            <li class="list-group-item">I would like to have an easy to use tool to document comments on individual data bits in a large data file preserved in excel, a database format, or something similar.</li>
            <li class="list-group-item">I would need more information on what a "software preservation quality tool" is to answer this. I do develop software that produces large amounts of data for both scientific and educational settings.</li>
            <li class="list-group-item">I'd like to use version control in my group among team members, but be able to see who did what.</li>
            <li class="list-group-item">I'm collecting a large amount of RFC 4898 TCP stack data that could use effective de-identification and management tools.</li>
            <li class="list-group-item">I'm not completely sure what you mean. Maybe this - I have old stopped-flow data created on an old Mac-driven system. It'd be pretty tough to look at those data now.</li>
            <li class="list-group-item">I'm not sure - we have code ( openmd.org ) and data (large trajectory files) that could be curated and archived better than on CRC afs space.</li>
            <li class="list-group-item">I'm not sure what you mean by "preservation quality tool."</li>
            <li class="list-group-item">I've planned on using the widely used version control system, git, for my code</li>
            <li class="list-group-item">I've worked with PSLC's DataShop in the past, and would love a more general tool for education data that is not action-level from a system.</li>
            <li class="list-group-item">Identifying cases where de-anonymization is possible; reliable provenance and timeliness indicators.</li>
            <li class="list-group-item">If I understand the question correctly, what would be useful to know is who worked on what, in what sequence, and what the exact updates were. Currently, much of this is accomplished through Github, Dropbox, and Microsoft Word tracking which has a combination of these abilities.</li>
            <li class="list-group-item">Interwoven data sets, with some common variables shared.Which variables are shared across sets changes.</li>
            <li class="list-group-item">It's not something I've thought very hard about, beyond satisfying NSF preservation requirements and enabling replication.</li>
            <li class="list-group-item">Keeping track of multiple projects over years</li>
            <li class="list-group-item">Large data and video files that must be made available</li>
            <li class="list-group-item">Large data files. Software preservation is done through Github/open source.</li>
            <li class="list-group-item">Linux Provenance Modules</li>
            <li class="list-group-item">Many tools exist... I never know the best one to select, and they're all difficult to search practically. They need to be user-friendly from the perspective of a data user, rather than the provider of data and the data manager</li>
            <li class="list-group-item">Maybe, but we develop quality assessment tools ourselves and can tailor them to our specific needs.</li>
            <li class="list-group-item">Method to archive assign DOIs to reusable workflows - see [our project]</li>
            <li class="list-group-item">Model My Watershed online GIS in the WikiWatershed.org toolkit</li>
            <li class="list-group-item">Montage image mosaic engine</li>
            <li class="list-group-item">More than I want to take the time to describe here</li>
            <li class="list-group-item">Much useful phylogenetic and microscope image analysis/control software becomes difficult or impossible to use only because Mac and PC operating systems change. Such software would still be useful if it were updated!</li>
            <li class="list-group-item">Multiple ad hoc bioinformatics pipelines vulnerable to changes in data and software versions.</li>
            <li class="list-group-item">My case is more on the data side, regarding workflow and provenance.</li>
            <li class="list-group-item">My main problem is WHERE to archive and preserve my data and software. I do not have a permanent (or even temporary) project website and I do not believe that NSF offers a place to archive project data. I often work with Stata, SAS or Excel, so I do not see a major problem with documentation and preservation unless, perhaps you wish to move everything to a flat ASCII file. A more serious preservation problem comes from using proprietary programs such as AnyLogic (www.anylogic.com) or TreeAge (www.treeage.com) where version changes can make it difficult to run older versions of these programs.</li>
            <li class="list-group-item">Need a better option for permanent archival and curation of datasets and minting of DOIs.</li>
            <li class="list-group-item">Need a tool that can help anonymize data prior to sharing.</li>
            <li class="list-group-item">Network-related experiments such as for Internet measurements or security/privacy are hard to undertake and replicate. Some tool to help "standardize" this type of experiment would be useful.</li>
            <li class="list-group-item">No, I am actually leading a data preservation project for NSF in my field of atmospheric chemistry so I wanted to see how these tools are being developed elsewhere.</li>
            <li class="list-group-item">No, I do mainly theoretical research and have minimal data needs.</li>
            <li class="list-group-item">No, at present our needs are met by existing tools (github, etc.)</li>
            <li class="list-group-item">No, but we have some advanced tools we've developed in house. We've been the subject of an ethnographic study on our software tool development, with significant overlap on this issue.</li>
            <li class="list-group-item">No, my field uses github which does some of this</li>
            <li class="list-group-item">No, the ones I checked above as most useful exist in Linux (e.g. version control systems)</li>
            <li class="list-group-item">No.  But we anticipate a need in the next 2 years.</li>
            <li class="list-group-item">No.  We make use of the OSF (osf.io) for collaboration and openness</li>
            <li class="list-group-item">No.  We use github, containerization, FAIR practices.</li>
            <li class="list-group-item">Nope - we archive our educational materials on partner websites</li>
            <li class="list-group-item">Not at this time but data management is a focus overall</li>
            <li class="list-group-item">Not at this time. My current approach is to store my software in public/private GitHub repos. If we want to release software developed as part of our research, we add an open source license to it and switch the repo from private to public.</li>
            <li class="list-group-item">Not really. I typically work with data that is stored on a community server and is accessed as needed. A key aspect of the data (seismic) is that it is in a nearly raw state and uniformly saved to maximize its ability to be used in new ways.</li>
            <li class="list-group-item">Not sure. It is not a priority given other considerations.</li>
            <li class="list-group-item">Not sure. We have CODAP, an online open source platform/library. It logs data of student actions. Does that come under this project?</li>
            <li class="list-group-item">Nothing in particular. In general I need a place to archive code and data for journal articles.</li>
            <li class="list-group-item">Possibly - too early to know for sure.  Ask again in 1 yr.</li>
            <li class="list-group-item">Possibly, but how would this be better than existing tools?</li>
            <li class="list-group-item">Possibly. I have many data sets that need to be archived.</li>
            <li class="list-group-item">Preservation of analytical data from archaeological assemblages</li>
            <li class="list-group-item">Preservation of mathematical software tools in a runnable, resusable form.</li>
            <li class="list-group-item">Preservation of software (and associated workflow) related to published papers</li>
            <li class="list-group-item">Preservation of theoretical software tools in HEP (FEWZ) http://gate.hep.anl.gov/fpetriello/FEWZ.html</li>
            <li class="list-group-item">Preservation of various levels of community data, and associated software</li>
            <li class="list-group-item">Preservation tools for qualitative data would be really useful!</li>
            <li class="list-group-item">Preserve large amounts of mysql dumps, python notebooks, etc</li>
            <li class="list-group-item">Preserving data</li>
            <li class="list-group-item">Presevration and tracking of custom data from annotated videos</li>
            <li class="list-group-item">Probably not at this time - we use some standard version control/tracking software for software tool development that works well for us currently</li>
            <li class="list-group-item">Probably not, but workflow preservation tools are interesting</li>
            <li class="list-group-item">Protocol navigator, it acquires meta data</li>
            <li class="list-group-item">Provenance tools</li>
            <li class="list-group-item">Providing permanent PI accounts on open git repos (e.g., bitbucket, github. etc) would go a long way to preserving data.   This is not so much the lack of a tool, but the lack of permanent funding to use a tool.</li>
            <li class="list-group-item">Public data hosting repository with permanent reference to be used in published articles. Perhaps a link/reference to the published article.</li>
            <li class="list-group-item">Quality tool, De-identification tool</li>
            <li class="list-group-item">SQL database</li>
            <li class="list-group-item">Secure, affordable/free long-term storage & data sharing option</li>
            <li class="list-group-item">So far I am posting my papers on ArXiv and don't have much other data that needs to be officially preserved.</li>
            <li class="list-group-item">Software stack "versioning" - ensuring software / scripts can be re-used long after release</li>
            <li class="list-group-item">Something like this [LIGO Document Control Center Portal url provided] but robust and distributable backed by a google strength team</li>
            <li class="list-group-item">Something to help with storage of experimental data in a single location, accessible from anywhere</li>
            <li class="list-group-item">Something to keep track of the multitude of different data-file types that our equipment produces, along with the metadata about experimental settings, etc. An easy way to organize and access this information that doesn't require a degree in computer science and only minimal understanding of databases is necessary for any tool to be adopted.</li>
            <li class="list-group-item">Standards for expressing and encoding provenance</li>
            <li class="list-group-item">System that can be used during development and quickly clean up and select what should be made public at the time of publication.</li>
            <li class="list-group-item">The biggest problem I have is that tools from prior work don't work due to software platforms evolving and the tool not getting updated or missing libraries.</li>
            <li class="list-group-item">The provenance tool would be most useful now, I'm doing some research on the history of glacier exploration in the western US</li>
            <li class="list-group-item">There are lots of places we could use help...</li>
            <li class="list-group-item">There is a great need to develop tools for capturing the provenance of biomodels (e.g. data sources and assumptions used to build models) to increase the comprehensibility of models and make models easier to modify and combine</li>
            <li class="list-group-item">There is a lot of development work out there already.</li>
            <li class="list-group-item">There is a strong need to be able to record corrections or supplemental data provided by users of our specimens (or their digital representations) as a layer separate from the original specimen metadata but searchable and displayable with original metadata</li>
            <li class="list-group-item">There is no standard for preserving/publishing NMR and other spectroscopy data for synthesized compounds, analogous to the CIF or PDB.</li>
            <li class="list-group-item">Too many! However, you might check out the work that Vicky Steeves at NYU has done. Although, youre probably already aware.</li>
            <li class="list-group-item">Tool to capture metadata with minimum user intervention would be of great help.</li>
            <li class="list-group-item">Tools that help provide appropriate metadata for computer simulation products I generate, following a template specified by a research program.</li>
            <li class="list-group-item">Tools that support the proposed Metabolomics Data Standards [respondent provided citations] </li>
            <li class="list-group-item">Unbdergraduate research projects that span multiple institutions and leverage course embedded research projects would greatly benfit from a shared data tool.</li>
            <li class="list-group-item">Unsure</li>
            <li class="list-group-item">Video and physiological data on orofacial movements in humans and animals</li>
            <li class="list-group-item">Virtual Reality applications</li>
            <li class="list-group-item">WE HAVE DEVELOPED AN APP THAT IS INTENDED TO GATHER CROWD SOURCED DATA. OUR CONCERN IS PERPETUATING THAT DATA</li>
            <li class="list-group-item">Way to easily organize, share, and preserve anonymity of data</li>
            <li class="list-group-item">We already have structures and processes in place for our data management.</li>
            <li class="list-group-item">We are curating (or helping programs curate) many biodiversity databases.  Helping with metadata, provenance, all this would be useful.</li>
            <li class="list-group-item">We are struggling with the increase in the usage VMs and Containers in research workflows. Developing a tool to aid in preservation/curation of thes would be extremely helpful.</li>
            <li class="list-group-item">We deposit data in public repositories such as the Gene Expression Omnibus -  [and] thus use their tools.</li>
            <li class="list-group-item">We don't have need at this time</li>
            <li class="list-group-item">We generate roughly 1 TB/yr of data, mostly in the form of stacks and arrays of 2D data (images) and spectra. We extensively use custom code to process this data. We co-develop technical manuscripts and presentations to communicate this data.</li>
            <li class="list-group-item">We have a good deal of cycle data from engines that must be preserved.</li>
            <li class="list-group-item">We have collected an archive of ~4000 images of 4th and 4th graders written work on fraction arithmetic problems. These images have each been tagged with ~10-15 identifiers. There are ~500 tags in total with a complex, nested structure. We are interested in developing tools to preserve and expand access to this archive.</li>
            <li class="list-group-item">We have some software we have developed on GitHub.  We have research data that we have had to construct our own RDBM schema for.   Deidentification of data and good metadata/ontologies would be helpful.</li>
            <li class="list-group-item">We have two sets of data, both involving numerous student papers as well as surveys, interviews, etc.</li>
            <li class="list-group-item">We just completed a full analysis of about 150 TB of particle physics data and are publishing the results. This effectively puts this data out in the public domain (partly by requirement of the journal). We do not currently have a way to do this efficiently. More broadly speaking, many other experiments at the national lab I am working at are in a similar situation and the lab itself does not provide for site-wide public data preservation solutions.</li>
            <li class="list-group-item">We maintain several data resources for both internal and external use and are interested in many such tools, more than a simple survey could cover.</li>
            <li class="list-group-item">We need a tool that will help our users better manage their data.  Manage means - deposit, attach metadata, attach DOIs, etc.</li>
            <li class="list-group-item">We need a tool to preserve the workflow in either xml or json format.</li>
            <li class="list-group-item">We need both data and software preservation tools, as well as training to use them for our projects that develop and apply first-principles calculations to carrier dynamics in materials</li>
            <li class="list-group-item">We need tools for data consolidation and maintenance</li>
            <li class="list-group-item">We use GitHub to preserve software -- that tool is sufficient.  GitHub does not handle large digitial files.</li>
            <li class="list-group-item">We use google docs and leave suggestions/comments</li>
            <li class="list-group-item">We use the tools freely available to us at [our university].  De-identified data is stored electronically on secure [university] servers to which only project and research team members have access. Hard-copy data is housed and managed by project evaluation and research team and PI, and kept for only 1 year following the project year they were collected.  For long-term use, data is housed in [departmental] secure file server.  Access to all research files on the server are protected using NTFS permissions, thus restricted to only those individuals with appropriate individual or group-level permissions.</li>
            <li class="list-group-item">We would dearly love a tool that helps us with a project that collects reams of image data (confocal and widefield) and then quantifies images. An ability to move between Zen Black, Zen Blue, Fuji, and other image analzysis software would be amazing - if this is possible?</li>
            <li class="list-group-item">We write code to perform our measurements (in Labview). It would be helpful to know what version of the software was running to take particular dataset. We have thought about using SVN or hg but these are cumbersome solutions</li>
            <li class="list-group-item">We're planning to develop a software preservation portal that might be an avenue for collaboration.</li>
            <li class="list-group-item">Wea re creating databases of images of forams including manual segmentation; We are creating databases of wearable data for individuals including physiological and environmental sensing</li>
            <li class="list-group-item">What I really need is a way to share resources (e.g., research-based instructional materials) that will be available to the public in perpetuity, without having to worry about maintaining a server, fixing breakage as infrastructure software evolves and updates, etc. (It's a problem many of us in Physics Education Research have.)</li>
            <li class="list-group-item">Working on a website to store curriculum modules.</li>
            <li class="list-group-item">Wow, that's a really interesting question.  My primary focus these days seems to be Visual Analytics.  I would be very interested in a system for preserving and annotating visualizations.  One of the most critical failures I see in final analyses of data, is that dozens of visualizations of the data may be generated, and these are so poorly annotated and cataloged that it becomes almost impossible to reproduce an identical visualization after even a few days of mental bit-rot.  The result is an ever-growing stack of randomly stored visual analyses that are essentially useless, because it's impossible to completely understand their content.  If you're actually interested in collaborating, this is a sufficiently interesting project that it might be worth talking to the NSF about specifically funding it.</li>
            <li class="list-group-item">Yes, I am part of a teem working on the development of software for biodiversity specialists. We are trying to envision all those issues in our product.</li>
            <li class="list-group-item">Yes, data about pharmaceutical quality and about lead assay results</li>
            <li class="list-group-item">Yes, metadata and persistent identifiers for both individual data and data bundles</li>
            <li class="list-group-item">Yes, we have extensive longitudinal data files and could use many types of tools to make it easier to archive the data set</li>
            <li class="list-group-item">Yes, we have lots of DNA sequence data that are difficult to archive and distribute. We use Github to make reproducible scripts also for dissemination but I am concerned about longevity issues.</li>
            <li class="list-group-item">Yes.  i am currently curating a metadata set for a five-year NSF project with multiple types of data in multiple formats.  i would be grateful for a tool that would help me do this curation efficiently and effectively.</li>
            <li class="list-group-item">Yes. As our work is funded by NSF, we have to comply with their desires for data management.</li>
            <li class="list-group-item">Yes. Currently working on the best format for preserving the data collected by the project.</li>
            <li class="list-group-item">Yes. Data base of atmospheric cloud measurments and data processing software</li>
            <li class="list-group-item">Yes. I need a tool to manage data and metadata and version control.</li>
            <li class="list-group-item">[respondent creates widely used softare] Currently the data and software are archived in different ways in different places.</li>
            <li class="list-group-item">[respondent describes a need where they have] de-identified data by hand in order to be able to publish the data and [need] for additional tools that remind about potential decisions, or that could even take a data set and automatically de-identify for public presentation, are potentially useful.</li>
            <li class="list-group-item">[respondent describes developing] an organization standard for brain imaging data  and [how] it would be great to get additional help with building out the validator and related tools</li>
            <li class="list-group-item">[respondent describes] large software project (Einstein Toolkit) which generates data (gravitational waveforms) which are used by other projects, where it would be important to have such tools.</li>
            <li class="list-group-item">[respondent has] Numerous investigators that has interest in facilitating the access, maintenance, and preservation of various kinds of science based models for managing water quality and living resources in the watershed, airshed, estuary, etc. and our investigators also of course have "data management" needs associated with their research grants and publications</li>
            <li class="list-group-item">[respondent provided URL to a paper on LACE2: Better Privacy-Preserving Data Sharing for Cross Project Defect Prediction] http://menzies.us/pdf/15lace2.pdf</li>
            <li class="list-group-item">[respondent provided grant number ] </li>
            <li class="list-group-item">[respondent] disseminates and archives modeling software, but relies on GitHub for version control. Preservation capability would be useful.</li>
            <li class="list-group-item">a GitHub.com plugin for scientific software</li>
            <li class="list-group-item">a tool that can keep software current/updated/working with the latest versions of OS and programming languages/compilers</li>
            <li class="list-group-item">a way to categorize and archive coding choices and decisions over organization of data</li>
            <li class="list-group-item">aerosol forcing data</li>
            <li class="list-group-item">all software stops working after a while because the environment changed</li>
            <li class="list-group-item">assistance with preservation of audio data</li>
            <li class="list-group-item">cloud-based storage associated with PI rather than institution.</li>
            <li class="list-group-item">collaboration tools.  Robust and compatible with Word, as easy too use as Google Drive, and tracks changes by user as well as Word does.</li>
            <li class="list-group-item">converting data in old (no longer used) data formats into plain text</li>
            <li class="list-group-item">data: large scale proteomics, transcriptomics and metabolomics</li>
            <li class="list-group-item">data</li>
            <li class="list-group-item">de-identifying</li>
            <li class="list-group-item">detailed research data</li>
            <li class="list-group-item">different tools for each category listed above</li>
            <li class="list-group-item">easier ways to resolve conflicts in github so that more people will use it without fearing entering a state they cannot navigate</li>
            <li class="list-group-item">git and mercurial already do a good job of most of these things.  What we need is for the NSF and other funding agencies to REQUIRE PIs to use good practices.</li>
            <li class="list-group-item">github</li>
            <li class="list-group-item">how to assess comprehensiveness of archive files</li>
            <li class="list-group-item">hydroshare.org could benefit from this.</li>
            <li class="list-group-item">i have data of all kinds and have not really thought about preservation</li>
            <li class="list-group-item">integrated use of identifiers from trusted sources (wikidata, orcid ...)</li>
            <li class="list-group-item">integration within Jupyter</li>
            <li class="list-group-item">jupyter notebooks on github</li>
            <li class="list-group-item">laboratory data on sediment transport experiments and computer models</li>
            <li class="list-group-item">large streams of time-series data that is interconnected even when in separate files</li>
            <li class="list-group-item">long-term data for several decades that contains information on multiple thousands of individuals</li>
            <li class="list-group-item">multivariate data analysis</li>
            <li class="list-group-item">no, but would be glad to use/test anything coming out of the project</li>
            <li class="list-group-item">no, our data quality is addressed at the analytical stage.</li>
            <li class="list-group-item">normally use github</li>
            <li class="list-group-item">not really - my research is mostly with VR tool-building and human subjects experiments in immersive virtual environments</li>
            <li class="list-group-item">not really because there are so many kinds of data and its only a trained human eye that can tell whether the original data along with experimental conditions was recorded completely.</li>
            <li class="list-group-item">not sure</li>
            <li class="list-group-item">not that I am immediately aware of, but I would be interested in exploring what is developed</li>
            <li class="list-group-item">no</li>
            <li class="list-group-item">personal diligence is better than hard-to-use tools</li>
            <li class="list-group-item">previously uncurated data associated with astronomical journal publications</li>
            <li class="list-group-item">refining specimen lists based on precision/resolution of locality data would be cool</li>
            <li class="list-group-item">repositories of benchmarks for research in VLSI CAD</li>
            <li class="list-group-item">synchrotron tomography data processing</li>
            <li class="list-group-item">the concept/ keyword tagging would be amazing.</li>
            <li class="list-group-item">tool checking  published metabolite tables for matching names to structure or DB identifiers</li>
            <li class="list-group-item">tool that helps to define and then confirm Climate and Forecast Metadata standards for unstructured grid ocean models</li>
            <li class="list-group-item">tool that summarizes the IP, terms of use, etc., from the data source</li>
            <li class="list-group-item">vr environment</li>
            <li class="list-group-item">we are struggling with project management tools due to a multi lab pipeline for generating data</li>
            <li class="list-group-item">will need to comply with NSF rules to make qualitative interview data publicly available to other scholars w anonymization</li>
            <li class="list-group-item">yeah, but it will be very complicated to develop.</li>
            <li class="list-group-item">yes massive amounts of field reconnaissance data collected by different PIs with different instruments across dates and locations.</li>
            <li class="list-group-item">yes, anonymizing data to share with others</li>
            <li class="list-group-item">yes, energy data that has bee collected</li>

        </ul>

        <hr>
        <h1>Researcher Behavior</h1>

        <h3>How familiar are you with tools used to share, publish, cite and preserve data or software?
        <small class="text-muted">(res)</small>
        </h3>
        <div id="res"></div>
    <script>
        make_pie('res',[
                ['Extremely familiar', 56], // green
                ['Very familiar', 199],     //  cyan
                ['Moderately familiar', 512], // yellow
                ['Slightly familiar', 421],  //  pink
                ['Not familiar at all', 240] // red
                //['no answer', 426],
                ]);
    </script>

    <h3>Do you anticipate publishing or sharing your own data or code over the next five years?
    <small class="text-muted">(res_pubshare_5)</small>
    </h3>
            <div id="res_pubshare_5"></div>
    <script>
        make_pie('res_pubshare_5',[
['Definitely will', 761],
['Probably will', 366],
['Might or might not', 178],
['Probably will not', 98],
['Definitely will not', 28]
//['no answer', 423]
]);
    </script>

    <h3>In the past, how often have you made your research data free to access, reuse, repurpose, and redistribute?
    <small class="text-muted">(res_open_data)</small>
    </h3>
    <div id="res_open_data"></div>
    <script>
        make_pie('res_open_data',[
['Always', 226],
['Usually', 480],
['About Half the Time', 203],
['Seldom', 373],
['Never', 137]
//['No Answer', 435]
]);
    </script>

    <h3>Is any of your data or code published or shared now on a repository or website?
    <small class="text-muted">(res_pubshare)</small>
    </h3>
    <div id="res_pubshare"></div>
    <script>
        make_pie('res_pubshare',[
['All that can be', 253],
['Most', 303],
['About Half', 186],
['A little', 436],
['None', 242]
//['No Answer', 434]
]);
    </script>

    <h3>In the past three years, have you or your research group made publicly accessible the following items through your or your institution's website or a third-party repository?
    <small class="text-muted">(res_open_data3)</small>
    </h3>
    <div id="res_open_data3"></div>
    <script>
        var res_open_data3 = c3.generate({
            bindto: "#res_open_data3",
            axis: {
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                order: null,
               colors: {
                    count: colorlist[0]
                },
                x: 'x',
                columns:[
                    ['x', 'Raw data', 'Structured databases', 'Processed data', 'Figure/Plot/Table data', 'Software'],
                    ['count', 502, 280, 721, 685, 581]
]}});
    </script>

    <h3>Do you need better tools to share, re-use, cite, publish or preserve your own or others' Data and/or Software?
    <small class="text-muted">(res_tools_share)</small>
    </h3>
    <div id="res_tools_share"></div>
    <script>
        var res_tools_share = c3.generate({
            bindto: "#res_tools_share",
            axis: {
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                order: null,
                colors: {
                    'to share': colorlist[0],
                    'to re-use': colorlist[1],
                    'to cite': colorlist[2],
                    'to publish': colorlist[3],
                    'to preserve': colorlist[4]
                },
                x: 'x',
                columns: [
                    ['x', 'Data', 'Software'],
                    ['to share', 719, 295],
                    ['to re-use', 535, 279],
                    ['to cite', 454, 269],
                    ['to publish', 498, 259],
                    ['to preserve', 815, 378]
]}});
    </script>

    <h3>When asked to submit keywords to describe your own or others' research is it usually:
    <small class="text-muted">(res_keywords)</small>
    </h3>
    <div id="res_keywords"></div>

    <script>
        make_pie('res_keywords',[
['Extremely easy', 209],
['Moderately easy', 857],
['Moderately difficult', 267],
['Extremely difficult', 20],
['I\'ve never had to submit keywords to describe my work', 48]
//['No Answer', 453]
]);
    </script>

    <h3>When asked to submit keywords to describe your own or others' resarch how accurately do the terms available usually describe your work?
    <small class="text-muted">(res_keywords_avail)</small>
    </h3>
    <div id="res_keywords_avail"></div>

    <script>
        make_pie('res_keywords_avail',[
['Very accurately', 176],
['Somewhat accurately', 989],
['Not Very Accurately', 161],
['Not Accurately at all', 20],
['I\'ve never had to submit keywords to describe my work', 51]
//['No Answer', 457]
]);
    </script>

    <h3>Does your employer require you to make any of your publications or data 
        openly available?
    <small class="text-muted">(res_employ_open)</small>
    </h3>
    <div id="res_employ_open"></div>

    <script>
        make_pie('res_employ_open',[
['Yes', 233],
['Not Yet, but they may in the future', 438],
['No', 724]
//['No Answer', 459]
]);
    </script>

    <h3>Do any of the organizations who fund your work require you to make any of your
        publications or data openly available?
    <small class="text-muted">(res_fund_open)</small>
    </h3>
    <div id="res_fund_open"></div>

    <script>
        make_pie('res_fund_open',[
['Yes', 775],
['Sometimes', 414],
['No', 210]
//['No Answer', 455]
]);
    </script>


    <h3>In your estimation, which of the following currently have the infrastructure 
required   to provide long-term public
access to your research data?
    <small class="text-muted">(res_pub_infrastruct)</small>
    </h3>
    <div id="res_pub_infrastruct"></div>

    <script>
        var res_pub_infrastruct = c3.generate({
            bindto: "#res_pub_infrastruct",
            axis: {
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                order: null,
                colors: {
                    Count: colorlist[0]
                },
                x: 'x',
                rows: [
                    ['x', 'Count'],
                    ['Your research group', 296 ], //1558],
                    ['Your institution',572 ], //1282],
                    ['Your funding agency',280], //1574],
                    ['Third-party repositories',736], //1118],
                    ['Journal publishers', 509] //1345]
]}});
    </script>

    <h3>Do you actively create and manage metadata to make sharing, finding, or 
        documenting provenance of your own or others' data or code easier?
    <small class="text-muted">(res_metadata)</small>
    </h3>
    <div id="res_metadata"></div>

    <script>
        make_pie("res_metadata", [
['Always', 85],
['Most of the time', 223],
['About half the time', 67],
['Sometimes', 457],
['Never', 398],
['What\'s Metadata?', 139]
//['No Answer', 485]
]);
    </script>

    <h3>How important to your work are Web-based applications that provide access to the 
following specialized resources?
    <small class="text-muted">(res_tools)</small>
    </h3>
    <div id="res_tools"></div>

    <script>
        var res_tools = c3.generate({
            bindto: "#res_tools",
            axis: {
                rotated: true,
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                order: null,
                colors: {
                    'Extremely important': colorlist[0],
                    'Important': colorlist[1],
                    'Unimportant': colorlist[2],
                    'Not at all Important': colorlist[3]
                },
                x: 'x',
                groups: [['Extremely important', 'Important', 'Unimportant',  'Not at all Important']],
                rows:[
                    // TODO: reorder columns
                    ['x', 'Extremely important', 'Important', 'Unimportant',  'Not at all Important'],
                    ['Computational tools', 272, 558, 260, 207],
                    ['Data collections', 426, 560, 198, 118],
                    ['Data analysis', 290, 567, 254, 184],
                    ['Simplified interfaces', 197, 426, 339, 334],
                    ['Platforms', 274, 606, 292, 120],
                    ['Finding Articles', 595, 536, 124, 47],
                    ['Rapidly Publishing', 174, 527, 453, 137],
                    ['Workflows', 146, 470, 421, 247],
                    ['Instruments', 241, 260, 289, 499],
                    ['Educational tools', 189, 590, 334, 177],
                    ['Citizen science', 111, 445, 446, 288]
]}});

    </script>

    <h3>Do you create and/or use software, code, or scripts in your research?
    <small class="text-muted">(res_code)</small>
    </h3>
    <div id="res_code"></div>

    <script>make_pie('res_code', [
['Always', 547],
['Most of the time', 257],
['About half the time', 84],
['Sometimes', 288],
['Never', 159]
//['No answer', 519]
]);
    </script>

    <h3>Have you ever authored software, code or scripts to analyze or produce your 
        data?
    <small class="text-muted">(res_author_sw)</small>
    </h3>
    <div id="res_author_sw"></div>

    <script>make_pie('res_author_sw', [
['Yes', 905],
['Can\'t Remember', 37],
['No', 394]
//['No answer', 518]
]);
    </script>


    <h3>Have you ever hired or supervised someone to author software code or scripts 
        to analyze or produce your data?
    <small class="text-muted">(res_hire_swdev)</small>
    </h3>
    <div id="res_hire_swdev"></div>

    <script>make_pie('res_hire_swdev', [
['Yes', 860],
['Can\'t remember', 22],
['No', 455]
//['No answer', 517]
]);
    </script>


    <h3>For others to reproduce your results would they need your software, code or scripts?
    <small class="text-muted">(res_reproduce)</small>
    </h3>
    <div id="res_reproduce"></div>

    <script>make_pie('res_reproduce', [
['Always', 155],
['Most of the time', 315],
['About half the time', 146],
['Sometimes', 400],
['Never', 316]
//['No answer', 522]
]);
    </script>

    <h3>Do you use or revise commercial and/or freeware software, scripts, or tools to 
analyze or produce your data more often than writing new code or hiring someone to write 
custom software to analyze or produce data for your project(s)?
    <small class="text-muted">(res_external_sw)</small>
    </h3>
    <div id="res_external_sw"></div>

    <script>make_pie('res_external_sw', [
['Always', 95],
['Most of the time', 291],
['About half the time', 227],
['Sometimes', 428],
['Never', 281]
//['No answer', 532]
]);
    </script>

        <hr>
        <h1>Developer Behavior</h1>

        <h3>The next questions are for those who develop, administer or maintain software and/or 
systems used to share, publish or preserve data or software. Are these sorts of tasks your 
responsibility?
    <small class="text-muted">(dev)</small>
        </h3>
        <div id="dev"></div>

    <script>make_pie('dev', [
['Yes', 213],
['Occasionally', 276],
['Never', 798],
//['No answer', 567]
]);
    </script>

    <h3>Do you collaboratively develop and/or publicly share code in an version 
        control repository like GitHub or bitbucket?
    <small class="text-muted">(dev_code_verCon)</small>
    </h3>

    <div id="dev_code_verCon"></div>

    <script>make_pie('dev_code_verCon', [
['Yes, collaboratively develop and publicly share in a code repository', 112],
['Yes, manage in a code repository but don\'t make public', 47],
['No, it\'s all managed at the team or dev level internally on developer machines or our local filesystems', 73],
['No, I only distribute binaries', 16],
['Prefer not to Answer', 19],
//['No answer', 9]
]);
    </script>

    <h3>Do you develop, administer, maintain or support any (select any that apply):
    <small class="text-muted">(dev_sw_dams)</small>
    </h3>
    <div id="dev_sw_dams"></div>

    <script>
        var dev_sw_dams = c3.generate({
            bindto: "#dev_sw_dams",
            axis: {
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                order: null,
                x: 'x',
                colors: {
                    Develop: colorlist[0],
                    Administer: colorlist[1],
                    Maintain: colorlist[2],
                    Support: colorlist[3]
                },
                rows:[
                    ['x', 'Develop', 'Administer', 'Maintain', 'Support'],
                    ['Share', 39, 51, 46, 43],
                    ['Publish or cite', 18, 33, 25, 28],
                    ['Preserve', 24, 38, 38, 38],
                    ['Other', 86, 64, 67, 64]
]}});
    </script>

    <h3>How long do you expect people to use the software you
develop, administer, 
maintain or support ?
    <small class="text-muted">(dev_sw_eol)</small>
    </h3>
    <div id="dev_sw_eol"></div>

    <script>make_pie('dev_sw_eol', [
['>10 years', 48],
['10 years', 15],
['5-10 years', 104],
['less than 5 years', 78]
//['No answer', 31]
]);
    </script>

    <h3>For the typical software you
develop, administer, maintain or support, how 
many users are there:
    <small class="text-muted">(dev_user_count)</small>
    </h3>
    <div id="dev_user_count"></div>

    <script>make_pie('dev_user_count', [
['over 50,000 users', 3],
['over 10,000 users', 6],
['over 1000 users', 13],
['500-1000 users', 19],
['More than 50, less than 500 users', 55],
['less than 50 users', 141]
//['No answer', 39]
]);
    </script>

    <h3>How do you typically license the software you develop? Select all that apply:
    <small class="text-muted">(dev_license)</small>
    </h3>
    <div id="dev_license"></div>

    <script>
        var dev_license = c3.generate({
            bindto: "#dev_license",
            axis: {
                x: { type: 'category'}
            },
            data: {
                type: 'bar',
                colors: {
                    Count: colorlist[0]
                },
                order: null,
                x: 'x',
                rows:[
                    ['x', 'Count'],
                    ['GPL', 87],
                    ['CC', 50],
                    ['Apache', 23],
                    ['MIT', 34],
                    ['Other', 35]
]}});
     </script>

     Some of the licenses mentioned in <em>Other</em>:
     <ul class="list-group">
         <li class="list-group-item">BSD (includes BSD 3-clause, and BSD3)</li>
         <li class="list-group-item">Apache</li>
         <li class="list-group-item">Not licensed</li>
         <li class="list-group-item">n/a</li>
     </ul>

<h3>Have you containerized any code to make sharing or distribution easier?
    <small class="text-muted">(dev_code_container)</small>
</h3>
<div id="dev_code_container"></div>

    <script>make_pie('dev_code_container', [['Yes', 33], ['No', 92]]);
    </script>

    </div>
    </body>
</html>
